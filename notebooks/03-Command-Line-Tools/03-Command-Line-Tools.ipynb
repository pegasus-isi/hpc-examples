{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Tools\n",
    "\n",
    "As mentioned before, running Pegasus is in a Jupyter notebook is very convenient for tutorials and for smaller workflows, but production workflows are most commonly submitted on dedicated HTCondor submit nodes using command line tools. This section of the tutorial uses the same workflow as we have seen in the previous sections, generated inside the notebook. Planning, submitting and checking status will be done using the command line tools.\n",
    "\n",
    "First, execute the following cell to generate the workflow. Note that we are just writing it out at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set Jupyter Environment\n",
    "\n",
    "We need to set PYTHONPATH for Pegasus libraries to be imported successfully in the notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pegasus_python_path=!pegasus-config --python \n",
    "import sys\n",
    "sys.path.append(pegasus_python_path.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create the Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify your SLURM information**\n",
    "\n",
    "At a minimum, you need to specify some variables that declare\n",
    "* the project/account under which your jobs run\n",
    "* the slurm partition to which the jobs should be submitted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variables for slurm cluster. \n",
    "# Please update according per your cluster\n",
    "slurm_partition=\"XXXXX\"\n",
    "slurm_account=\"YYYYY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from Pegasus.api import *\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "EXECUTABLES_DIR = Path(BASE_DIR / \"..\" / \"..\" / \"executables\").resolve()\n",
    "\n",
    "# --- Properties ---------------------------------------------------------------\n",
    "props = Properties()\n",
    "props[\"pegasus.monitord.encoding\"] = \"json\"                                                                    \n",
    "props[\"pegasus.catalog.workflow.amqp.url\"] = \"amqp://friend:donatedata@msgs.pegasus.isi.edu:5672/prod/workflows\"\n",
    "props[\"pegasus.mode\"] = \"tutorial\" # speeds up tutorial workflows - remove for production ones\n",
    "props.write() # written to ./pegasus.properties \n",
    "\n",
    "# --- Replicas -----------------------------------------------------------------\n",
    "with open(\"f.a\", \"w\") as f:\n",
    "   f.write(\"This is sample input to KEG\")\n",
    "\n",
    "fa = File(\"f.a\").add_metadata(creator=\"ryan\")\n",
    "rc = ReplicaCatalog().add_replica(\"local\", fa, Path(\".\").resolve() / \"f.a\")\n",
    "\n",
    "# --- Transformations ----------------------------------------------------------\n",
    "preprocess = Transformation(\n",
    "                \"preprocess\",\n",
    "                site=\"local\",\n",
    "                pfn=\"{}/pegasus-keg.py\".format(EXECUTABLES_DIR),\n",
    "                is_stageable=True,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            )\n",
    "\n",
    "findrange = Transformation(\n",
    "                \"findrange\",\n",
    "                site=\"local\",\n",
    "                pfn=\"{}/pegasus-keg.py\".format(EXECUTABLES_DIR),\n",
    "                is_stageable=True,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            )\n",
    "\n",
    "analyze = Transformation(\n",
    "                \"analyze\",\n",
    "                site=\"local\",\n",
    "                pfn=\"{}/pegasus-keg.py\".format(EXECUTABLES_DIR),\n",
    "                is_stageable=True,\n",
    "                arch=Arch.X86_64,\n",
    "                os_type=OS.LINUX\n",
    "            ) \n",
    "\n",
    "tc = TransformationCatalog().add_transformations(preprocess, findrange, analyze)\n",
    "\n",
    "# --- Sites -----------------------------------------------------------------\n",
    "# add a local site with an optional job env file to use for compute jobs\n",
    "shared_scratch_dir = \"{}/LOCAL/work\".format(BASE_DIR)\n",
    "local_storage_dir = \"{}/LOCAL/storage\".format(BASE_DIR)\n",
    "\n",
    "# some variables for slurm cluster. you may wish to update\n",
    "# them for your needs\n",
    "slurm_partition=\"main\"\n",
    "slurm_account=\"hpcsuppt_613\"\n",
    "\n",
    "local = Site(\"local\") \\\n",
    "    .add_directories(\n",
    "    Directory(Directory.SHARED_SCRATCH, shared_scratch_dir)\n",
    "        .add_file_servers(FileServer(\"file://\" + shared_scratch_dir, Operation.ALL)),\n",
    "    Directory(Directory.LOCAL_STORAGE, local_storage_dir)\n",
    "        .add_file_servers(FileServer(\"file://\" + local_storage_dir, Operation.ALL)))\n",
    "\n",
    "slurm_scratch_dir = \"{}/SLURM/work\".format(BASE_DIR)\n",
    "slurm_storage_dir = \"{}/SLURM/storage\".format(BASE_DIR)\n",
    "\n",
    "slurm = Site(\"slurm\")\\\n",
    "    .add_directories(\n",
    "    Directory(Directory.SHARED_SCRATCH, slurm_scratch_dir)\n",
    "        .add_file_servers(FileServer(\"file://\" + slurm_scratch_dir, Operation.ALL)),\n",
    "    Directory(Directory.LOCAL_STORAGE, slurm_storage_dir)\n",
    "        .add_file_servers(FileServer(\"file://\" + slurm_storage_dir, Operation.ALL)))\n",
    "\n",
    "slurm.add_pegasus_profile(\n",
    "                        style=\"glite\",\n",
    "                        queue=slurm_partition,\n",
    "                        project=slurm_account,\n",
    "                        data_configuration=\"nonsharedfs\",\n",
    "                        auxillary_local=\"true\",\n",
    "                        nodes=1,\n",
    "                        ppn=1,\n",
    "                        runtime=1800,\n",
    "                        clusters_num=2\n",
    "                    )\n",
    "slurm.add_condor_profile(grid_resource=\"batch slurm\")\n",
    "\n",
    "sc = SiteCatalog()\\\n",
    "   .add_sites(local)\\\n",
    "   .add_sites(slurm)\\\n",
    "\n",
    "# --- Workflow -----------------------------------------------------------------\n",
    "'''\n",
    "                     [f.b1] - (findrange) - [f.c1]\n",
    "                     /                             \\\n",
    "[f.a] - (preprocess)                               (analyze) - [f.d]\n",
    "                     \\                             /\n",
    "                     [f.b2] - (findrange) - [f.c2]\n",
    "\n",
    "'''\n",
    "wf = Workflow(\"blackdiamond\")\n",
    "\n",
    "fb1 = File(\"f.b1\")\n",
    "fb2 = File(\"f.b2\")\n",
    "job_preprocess = Job(preprocess)\\\n",
    "                    .add_args(\"-a\", \"preprocess\", \"-T\", \"3\", \"-i\", fa, \"-o {},{}\".format(fb1, fb2))\\\n",
    "                    .add_inputs(fa)\\\n",
    "                    .add_outputs(fb1, fb2)\n",
    "\n",
    "fc1 = File(\"f.c1\")\n",
    "job_findrange_1 = Job(findrange)\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb1, \"-o\", fc1)\\\n",
    "                    .add_inputs(fb1)\\\n",
    "                    .add_outputs(fc1)\n",
    "\n",
    "fc2 = File(\"f.c2\")\n",
    "job_findrange_2 = Job(findrange)\\\n",
    "                    .add_args(\"-a\", \"findrange\", \"-T\", \"3\", \"-i\", fb2, \"-o\", fc2)\\\n",
    "                    .add_inputs(fb2)\\\n",
    "                    .add_outputs(fc2)\n",
    "\n",
    "fd = File(\"f.d\")\n",
    "job_analyze = Job(analyze)\\\n",
    "                .add_args(\"-a\", \"analyze\", \"-T\", \"3\", \"-i {},{}\".format(fc1, fc2), \"-o\", fd)\\\n",
    "                .add_inputs(fc1, fc2)\\\n",
    "                .add_outputs(fd)\n",
    "\n",
    "wf.add_jobs(job_preprocess, job_findrange_1, job_findrange_2, job_analyze)\n",
    "wf.add_replica_catalog(rc)\n",
    "wf.add_transformation_catalog(tc)\n",
    "wf.add_site_catalog(sc)\n",
    "wf.write()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Opening the Jupyter terminal\n",
    "\n",
    "To open a new terminal window, navigate back to the listings tab of Jupyter notebook. This is where you have been opening all the sections from. In the top right corner of the listing, click `New` and then `Terminal`. It looks something like:\n",
    "\n",
    "![Terminal Start](../images/terminal-start.png)\n",
    "\n",
    "Once started, arrange your browser tabs/windows side by side so that you can see these instructions and the terminal window at the same time. In the following sections, when you are presented with a `$`, that means it is a command you can type in or copy and paste into the terminal window. Sometimes you have to substitute your own values and that is highlighted with square brackets `[]`.\n",
    "\n",
    "First, cd to the correct directory:\n",
    "\n",
    "    $ cd ~/hpc-examples/notebooks/03-Command-Line-Tools/\n",
    "    \n",
    "If you run `ls`, you should see these files:\n",
    "\n",
    "    $ ls\n",
    "    03-Command-Line-Tools.ipynb\n",
    "    f.a\n",
    "    pegasus.properties\n",
    "    workflow.yml\n",
    "    \n",
    "The 3 latter ones were just generated by the cell above.\n",
    "\n",
    "## 3. Planning and submitting\n",
    "\n",
    "\n",
    "\n",
    "    $ pegasus-plan --sites slurm --submit workflow.yml\n",
    "    \n",
    "In the output of the plan command, you will see a reference to several other Pegasus commands such as pegasus-status. More importantly, a workflow directory was generated for the new workflow instance. This directory is the handle to the workflow instance and used by Pegasus command line tools. Some useful tools to know about:\n",
    "\n",
    " * **pegasus-status -v [wfdir]** Provides status on a workflow instance\n",
    " * **pegasus-analyzer [wfdir]** Provides debugging clues why a workflow failed. Run this after a workflow has failed\n",
    " * **pegasus-statistics [wfdir]** Provides statistics, such as walltimes, on a workflow after it has completed\n",
    " * **pegasus-remove [wfdir]** Removes a workflow from the system\n",
    "\n",
    "\n",
    "## 4. Workflow status\n",
    "\n",
    "Use the workflow directory given in the output of the `pegasus-plan` command to determine the status of your workflow:\n",
    "\n",
    "    $ pegasus-status -l [wfdir]\n",
    "\n",
    "The flag `-l` gives you more verbose output. Please see `pegasus-status --help` to see all the options available.\n",
    "\n",
    "You can keep running `pegasus-status` until the workflow has completed, or you can use the `-w` flag to mimic the `wait()` function we used in the API. This flag will make `pegasus-status` run periodically until the workflow is complete:\n",
    "\n",
    "    $ pegasus-status -l -w 30 [wfdir]\n",
    "    \n",
    "\n",
    "## 5. Workflow statistics\n",
    "\n",
    "Once the workflow is complete, you can extract statistics from the provenance database:\n",
    "\n",
    "    $ pegasus-statistics -s all [wfdir]\n",
    "\n",
    " \n",
    "## What's Next?\n",
    "\n",
    "The next notebook is `04-Containers/` that shows you how to use a docker container for executing jobs in your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
